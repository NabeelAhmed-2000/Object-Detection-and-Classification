{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3b54303-1cec-43b0-a96a-2f9cc84efeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2                                                      # For importing OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08faaa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt                                 # For importing matplot library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "077224ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time                                                     # For importing time module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4cc1989",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = 'ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt'    # This is the configuration file\n",
    "frozen_model = 'frozen_inference_graph.pb'                      # This is the pre-trained TensorFlow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "542ee07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cv2.dnn_DetectionModel(frozen_model, config_file)       # For loading the model and configuration file into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58f7a8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "classLabels = []                                                # Creating an empty List in python\n",
    "file_name = 'labels.txt'                                        # Reading the contents of 'Labels.txt'\n",
    "with open(file_name, 'rt') as fpt:\n",
    "    classLabels = fpt.read().rstrip('\\n').split('\\n')           # Transferring the contents of 'Labels.txt' to 'classLabels' list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c191bfd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "< cv2.dnn.Model 000002072A894890>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.setInputSize(320, 320)                                    # Input size is 320x320 as defined in the configuration file\n",
    "model.setInputScale(1.0 / 127.5)                                # Scaling the Grey level (0-255) of image i.e. 255/2=127.5\n",
    "model.setInputMean((127.5, 127.5, 127.5))                       # Taking mean of 127.5 as input domain of MobileNet is [-1,1]\n",
    "model.setInputSwapRB(True)                                      # Automatically converts image from BGR to RGB color space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f995c5e1-f423-43e2-bff6-19d186142bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Real-Time Object Detection through Webcam\n",
      "2. Non-Real-Time Object Detection through Sample Video\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Select detection mode (1 or 2):  1\n",
      "Enter webcam width (e.g., 640):  1920\n",
      "Enter webcam height (e.g., 480):  1080\n"
     ]
    }
   ],
   "source": [
    "sample_video = \"original_sample_video.mp4\"                      # provide the name of the sample video\n",
    "\n",
    "# Prompt for mode selection with numeric input\n",
    "print(\"1. Real-Time Object Detection through Webcam\")\n",
    "print(\"2. Non-Real-Time Object Detection through Sample Video\")\n",
    "\n",
    "mode = input(\"Select detection mode (1 or 2): \").strip()\n",
    "\n",
    "# Validate the input\n",
    "while mode not in ['1', '2']:\n",
    "    print(\"Invalid option!\")\n",
    "    mode = input(\"Select detection mode (1 or 2): \").strip()\n",
    "\n",
    "# Get webcam resolution if real-time mode is chosen\n",
    "if mode == '1':                                                 # Real-Time Object Detection through Webcam\n",
    "    webcam_width = int(input(\"Enter webcam width (e.g., 640): \"))\n",
    "    webcam_height = int(input(\"Enter webcam height (e.g., 480): \"))\n",
    "    cap = cv2.VideoCapture(0)  # Open webcam\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, webcam_width)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, webcam_height)\n",
    "    video_width, video_height = webcam_width, webcam_height     # Use webcam resolution\n",
    "else:                                                           # Non-Real-Time Detection through Sample Video\n",
    "    cap = cv2.VideoCapture(sample_video)                        # Load the video\n",
    "    video_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))        # Get video resolution\n",
    "    video_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "if not cap.isOpened():                                          # Check if the video or webcam opened correctly\n",
    "    raise IOError(\"Cannot open video or webcam!\")\n",
    "\n",
    "font_scale = 2\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "\n",
    "cv2.namedWindow('Object Detection Tutorial', cv2.WINDOW_NORMAL)    # Create a normal window\n",
    "\n",
    "fullscreen = True                                               # Flag to toggle fullscreen mode\n",
    "cv2.setWindowProperty('Object Detection Tutorial', cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "\n",
    "# Variables for FPS calculation\n",
    "frame_count = 0\n",
    "start_time = time.time()\n",
    "avg_fps = 0\n",
    "fps_window = 30                                                 # Number of frames to average over for smooth FPS calculation\n",
    "frame_times = []\n",
    "\n",
    "aspect_ratio = video_width / video_height                       # Calculate the aspect ratio once before the loop starts\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"End of video or cannot fetch frame.\")\n",
    "        break                                                   # Break if the video ends or frame cannot be read\n",
    "\n",
    "    frame_start_time = cv2.getTickCount()                       # Real-time FPS calculation (start measuring time for each frame)\n",
    "\n",
    "    # Get the screen resolution\n",
    "    screen_width = cv2.getWindowImageRect('Object Detection Tutorial')[2]\n",
    "    screen_height = cv2.getWindowImageRect('Object Detection Tutorial')[3]\n",
    "\n",
    "    # Use the pre-calculated aspect ratio for scaling\n",
    "    if screen_width / screen_height > aspect_ratio:\n",
    "        display_height = screen_height\n",
    "        display_width = int(display_height * aspect_ratio)\n",
    "    else:\n",
    "        display_width = screen_width\n",
    "        display_height = int(display_width / aspect_ratio)\n",
    "\n",
    "    resized_frame = cv2.resize(frame, (display_width, display_height))\n",
    "\n",
    "    # Center the frame with padding if necessary\n",
    "    top_padding = (screen_height - display_height) // 2\n",
    "    left_padding = (screen_width - display_width) // 2\n",
    "\n",
    "    bordered_frame = cv2.copyMakeBorder(resized_frame, top_padding, top_padding, left_padding, left_padding, cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
    "\n",
    "    try:\n",
    "        # Detect objects in the original frame\n",
    "        ClassIndex, confidence, bbox = model.detect(frame, confThreshold=0.55)\n",
    "        if len(ClassIndex) != 0:\n",
    "            for ClassInd, conf, boxes in zip(ClassIndex.flatten(), confidence.flatten(), bbox):\n",
    "                if ClassInd <= 90:\n",
    "                    # Adjust bounding box coordinates to account for padding\n",
    "                    adjusted_box = [\n",
    "                        int(boxes[0] * display_width / video_width) + left_padding,\n",
    "                        int(boxes[1] * display_height / video_height) + top_padding,\n",
    "                        int(boxes[2] * display_width / video_width),\n",
    "                        int(boxes[3] * display_height / video_height)\n",
    "                    ]\n",
    "\n",
    "                    cv2.rectangle(bordered_frame, adjusted_box, (255, 0, 0), 2)\n",
    "\n",
    "                    # Format the label text: \"Class Name: Confidence%\"\n",
    "                    label = f\"{classLabels[ClassInd - 1]}: {conf:.2f}\"    # Format confidence to 2 decimal places\n",
    "\n",
    "                    # Get text size to avoid cutting off text\n",
    "                    (text_width, text_height), _ = cv2.getTextSize(label, font, font_scale, 2)\n",
    "\n",
    "                    # Adjust text position to make sure it's inside the image\n",
    "                    x, y = adjusted_box[0] + 10, adjusted_box[1] + 40\n",
    "\n",
    "                    # Check if the text goes beyond the image boundaries\n",
    "                    if x + text_width > screen_width:\n",
    "                        x = screen_width - text_width - 10      # Adjust x if text overflows on the right\n",
    "                    if y + text_height > screen_height:\n",
    "                        y = screen_height - text_height - 10    # Adjust y if text overflows at the bottom\n",
    "\n",
    "                    # Display the label with adjusted position\n",
    "                    cv2.putText(bordered_frame, label, (x, y), font, fontScale=font_scale, color=(0, 255, 0), thickness=2)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in detection: {e}\")\n",
    "\n",
    "    # Calculate FPS for current frame\n",
    "    frame_end_time = cv2.getTickCount()\n",
    "    time_per_frame = (frame_end_time - frame_start_time) / cv2.getTickFrequency()\n",
    "    real_time_fps = 1 / time_per_frame\n",
    "\n",
    "    frame_times.append(time_per_frame)                          # Maintain running sum of frame times\n",
    "\n",
    "    # Remove the oldest frame time if the window exceeds the size\n",
    "    if len(frame_times) > fps_window:\n",
    "        frame_times.pop(0)\n",
    "\n",
    "    avg_fps = fps_window / sum(frame_times)                     # Calculate average FPS\n",
    "\n",
    "    # Display FPS on the frame\n",
    "    fps_text = f\"Real-time FPS: {real_time_fps:.2f} | Avg FPS: {avg_fps:.2f}\"\n",
    "    cv2.putText(bordered_frame, fps_text, (10, 35), font, fontScale=font_scale, color=(0, 0, 255), thickness=2)\n",
    "\n",
    "    cv2.imshow('Object Detection Tutorial', bordered_frame)     # Show the frame with FPS\n",
    "\n",
    "    key = cv2.waitKey(10) & 0xFF                                # Exit when 'q' is pressed\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('f'):                                       # Toggle fullscreen mode when 'f' is pressed\n",
    "        fullscreen = not fullscreen\n",
    "        if fullscreen:\n",
    "            cv2.setWindowProperty('Object Detection Tutorial', cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "        else:\n",
    "            cv2.setWindowProperty('Object Detection Tutorial', cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_NORMAL)\n",
    "\n",
    "# Release the video capture and destroy all OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff1ca54-bb61-4c27-b423-929a54077ed0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
